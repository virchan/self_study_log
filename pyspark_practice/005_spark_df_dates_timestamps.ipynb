{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c819a2",
   "metadata": {},
   "source": [
    "# Dates and Timestamps in Spark Dataframe\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "<ol style = \"type:1\">\n",
    "    <li><a href = \"#ref\">References</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa21a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efd0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/virchan/spark-3.3.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bda212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75b87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output hidden\n",
    "spark = SparkSession.builder.appName(\"dates\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c20053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"appl_stock.csv\", \n",
    "                    header = True,\n",
    "                    inferSchema = True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a767cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2010, 1, 4, 0, 0), Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323d3ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|               Date|              Open|\n",
      "+-------------------+------------------+\n",
      "|2010-01-04 00:00:00|        213.429998|\n",
      "|2010-01-05 00:00:00|        214.599998|\n",
      "|2010-01-06 00:00:00|        214.379993|\n",
      "|2010-01-07 00:00:00|            211.75|\n",
      "|2010-01-08 00:00:00|        210.299994|\n",
      "|2010-01-11 00:00:00|212.79999700000002|\n",
      "|2010-01-12 00:00:00|209.18999499999998|\n",
      "|2010-01-13 00:00:00|        207.870005|\n",
      "|2010-01-14 00:00:00|210.11000299999998|\n",
      "|2010-01-15 00:00:00|210.92999500000002|\n",
      "+-------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Date\", \"Open\"]).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c61253",
   "metadata": {},
   "source": [
    "Spark has various functions on handling datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac4c489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (dayofmonth, \n",
    "                                   hour, \n",
    "                                   dayofyear, \n",
    "                                   month, \n",
    "                                   year, \n",
    "                                   weekofyear, \n",
    "                                   format_number, \n",
    "                                   date_format\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4a8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|dayofmonth(Date)|\n",
      "+----------------+\n",
      "|               4|\n",
      "|               5|\n",
      "|               6|\n",
      "|               7|\n",
      "|               8|\n",
      "|              11|\n",
      "|              12|\n",
      "|              13|\n",
      "|              14|\n",
      "|              15|\n",
      "+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofmonth(df[\"Date\"])).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "311f758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|hour(Date)|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(hour(df[\"Date\"])).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57e55d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(Date)|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(month(df[\"Date\"])).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8030fe",
   "metadata": {},
   "source": [
    "We can create a `\"Year\"` column with the `.withColumn()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61661ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df.withColumn(\"Year\", year(df[\"Date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e520eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+------------------+------------------+---------+------------------+----+\n",
      "|               Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|Year|\n",
      "+-------------------+----------+----------+------------------+------------------+---------+------------------+----+\n",
      "|2010-01-04 00:00:00|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|2010|\n",
      "|2010-01-05 00:00:00|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|2010|\n",
      "|2010-01-06 00:00:00|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|2010|\n",
      "|2010-01-07 00:00:00|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|2010|\n",
      "|2010-01-08 00:00:00|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|2010|\n",
      "+-------------------+----------+----------+------------------+------------------+---------+------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71384fef",
   "metadata": {},
   "source": [
    "We can then group by the year, and average everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ebb2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------------------+------------------+--------------------+------------------+---------+\n",
      "|Year|         avg(Open)|         avg(High)|          avg(Low)|        avg(Close)|         avg(Volume)|    avg(Adj Close)|avg(Year)|\n",
      "+----+------------------+------------------+------------------+------------------+--------------------+------------------+---------+\n",
      "|2015|120.17575393253965|121.24452385714291| 118.8630954325397|120.03999980555547|  5.18378869047619E7|115.96740080555561|   2015.0|\n",
      "|2013| 473.1281355634922| 477.6389272301587|468.24710264682557| 472.6348802857143|          1.016087E8| 62.61798788492063|   2013.0|\n",
      "|2014| 295.1426195357143|297.56103184523823| 292.9949599801587| 295.4023416507935| 6.315273055555555E7| 87.63583323809523|   2014.0|\n",
      "|2012|     576.652720788| 581.8254008040001| 569.9211606079999| 576.0497195640002|       1.319642044E8| 74.81383696800002|   2012.0|\n",
      "|2016|104.50777772619044| 105.4271825436508|103.69027771825397|104.60400786904763|  3.84153623015873E7|103.15032854761901|   2016.0|\n",
      "|2010| 259.9576190992064|262.36880881349214|256.84761791269847| 259.8424600000002|1.4982631666666666E8|33.665072424603196|   2010.0|\n",
      "|2011|364.06142773412705| 367.4235704880951|360.29769878174613|364.00432532142867|1.2307474166666667E8| 47.16023692063492|   2011.0|\n",
      "+----+------------------+------------------+------------------+------------------+--------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.groupBy(\"Year\").mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf75034",
   "metadata": {},
   "source": [
    "To select a particular column (list) from the dataframe,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "433798ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = newdf.groupBy(\"Year\").mean().select([\"Year\", \"avg(Close)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0368b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|        avg(Close)|\n",
      "+----+------------------+\n",
      "|2015|120.03999980555547|\n",
      "|2013| 472.6348802857143|\n",
      "|2014| 295.4023416507935|\n",
      "|2012| 576.0497195640002|\n",
      "|2016|104.60400786904763|\n",
      "|2010| 259.8424600000002|\n",
      "|2011|364.00432532142867|\n",
      "+----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a676f1",
   "metadata": {},
   "source": [
    "We rename the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1422be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = result.withColumnRenamed(\"avg(Close)\", \"Average Closing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e96b9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|   Average Closing|\n",
      "+----+------------------+\n",
      "|2015|120.03999980555547|\n",
      "|2013| 472.6348802857143|\n",
      "|2014| 295.4023416507935|\n",
      "|2012| 576.0497195640002|\n",
      "|2016|104.60400786904763|\n",
      "|2010| 259.8424600000002|\n",
      "|2011|364.00432532142867|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f06826",
   "metadata": {},
   "source": [
    "Next, we round the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3275a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|Avg Close|\n",
      "+----+---------+\n",
      "|2015|   120.04|\n",
      "|2013|   472.63|\n",
      "|2014|   295.40|\n",
      "|2012|   576.05|\n",
      "|2016|   104.60|\n",
      "|2010|   259.84|\n",
      "|2011|   364.00|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_result.select([\"Year\", format_number(\"Average Closing\", 2).alias(\"Avg Close\")]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023264fc",
   "metadata": {},
   "source": [
    "## <a name = \"ref\">References</a>\n",
    "\n",
    "<ol style = \"type:1\">\n",
    "    <li>Jose Portilla. Spark and Python for Big Data with PySpark.</li>\n",
    "    <li>Apache Spark. <a href = \"https://spark.apache.org/docs/latest/api/python/\">https://spark.apache.org/docs/latest/api/python/</a>.</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
