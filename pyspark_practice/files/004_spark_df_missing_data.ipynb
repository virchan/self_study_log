{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a28423",
   "metadata": {},
   "source": [
    "# Missing Data in Spark Dataframe\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "<ol style = \"type:1\">\n",
    "    <li><a href = \"#naanddrop\"><code>`na`</code> and <code>`drop`</code></a></li>\n",
    "    <li><a href = \"#fill\">Filling Missing Data with <code>`fill`</code></a></li>\n",
    "    <li><a href = \"#ref\">References</a></li>\n",
    "</ol>\n",
    "\n",
    "## <a name = \"naanddrop\">`na` and `drop`</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7244b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d7a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/virchan/spark-3.3.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a693b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32433fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output hidden\n",
    "spark = SparkSession.builder.appName(\"miss\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f53eeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"ContainsNull.csv\", \n",
    "               header = True, \n",
    "               inferSchema = True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d923d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f5a6f",
   "metadata": {},
   "source": [
    "For any dataframe, we can use the `.na()` method to drop, fill, etc with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03f7c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f0457",
   "metadata": {},
   "source": [
    "We can also specify a threshold arugment. For example, by passing in `thresh = 2`, we are requesting rows that have at least two non-null values. (I.e., we get rows with at most one null value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706a6a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(thresh = 2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fa968",
   "metadata": {},
   "source": [
    "There is another argument `how`. Passing in `how = 'any'` means we are dropping rows with <i>any</i> null values. (I.e., we get the dense part of the dataframe.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9818a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = \"any\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5431a3",
   "metadata": {},
   "source": [
    "Passing in `how = 'all'` means we are dropping rows with <i>all</i> null values. (I.e., we are removing empty rows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3146c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = \"all\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e426674",
   "metadata": {},
   "source": [
    "If you want to consider only a certain column as far as missing data, we can clarify that with the `subset` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3da482f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset = [\"Sales\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0f1de",
   "metadata": {},
   "source": [
    "# <a name = \"fill\">Filling Missing Data with `fill`</a>\n",
    "\n",
    "We need to pay attention to data types when filling missing data. In order words, we need to make good use of `.printSchema()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a95cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2eed4",
   "metadata": {},
   "source": [
    "We have two string columns and one double column. Say we try the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b1b473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|  Id|      Name|Sales|\n",
      "+----+----------+-----+\n",
      "|emp1|      John| null|\n",
      "|emp2|FILL VALUE| null|\n",
      "|emp3|FILL VALUE|345.0|\n",
      "|emp4|     Cindy|456.0|\n",
      "+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"FILL VALUE\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a52298",
   "metadata": {},
   "source": [
    "What it does is it fills in the value `FILL VALUE` to any string column. If we put in numbers, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89afedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|  0.0|\n",
      "|emp2| null|  0.0|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963cd5d",
   "metadata": {},
   "source": [
    "All null values in numeric columns are replaced with the value 0. Of course, in general we will have to specify the columns to fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5d919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| null|\n",
      "|emp2|No Name| null|\n",
      "|emp3|No Name|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"No Name\", subset = [\"Name\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b44fbe",
   "metadata": {},
   "source": [
    "A common practice is filling missing numerica values with average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7a0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15ef7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = df.select(mean(df[\"Sales\"])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025ec46",
   "metadata": {},
   "source": [
    "Let's unpack this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bc45ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(Sales)=400.5)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4828c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(avg(Sales)=400.5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0eafba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b4784",
   "metadata": {},
   "source": [
    "Alternatively, can do it with dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f334bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg(Sales)': 400.5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7fbecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val[0].asDict()[\"avg(Sales)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687da23",
   "metadata": {},
   "source": [
    "To replace missing values with mean value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f633d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sales = mean_val[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24caae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(mean_sales, [\"Sales\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36139629",
   "metadata": {},
   "source": [
    "Alternatively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "750d7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(df.select(mean(df[\"Sales\"])).collect()[0][0], [\"Sales\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d821b",
   "metadata": {},
   "source": [
    "## <a name = \"ref\">References</a>\n",
    "\n",
    "<ol style = \"type:1\">\n",
    "    <li>Jose Portilla. Spark and Python for Big Data with PySpark.</li>\n",
    "    <li>Apache Spark. <a href = \"https://spark.apache.org/docs/latest/api/python/\">https://spark.apache.org/docs/latest/api/python/</a>.</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
