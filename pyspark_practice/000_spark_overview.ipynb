{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad44f1d",
   "metadata": {},
   "source": [
    "# Spark Overview\n",
    "\n",
    "## Table of Content\n",
    "<ol style = \"type:1\">\n",
    "    <li><a href = \"#intro\">Introduction</a></li>\n",
    "    <li><a href = \"#rddtransformaction\">RDD Transformations and Actions</a></li>\n",
    "    <li><a href = \"#mapvsflatmap\"> <code>map</code> vs <code>flatMap</code></a></li>\n",
    "    <li><a href = \"#keyandvaluepairs\">Key and Value Pairs</a></li>\n",
    "    <li><a href = \"#reducebykey\">Reduce-by-Key Statement</a></li>\n",
    "    <li><a href = \"#ref\">References</a></li>\n",
    "</ol>\n",
    "\n",
    "## <a name = \"#intro\">Introduction</a>\n",
    "\n",
    "A Spark context represents the connection to the spark cluster. It can be used in creating **resilient distributed dataset (RDD)**, and broadcast variables on that cluster. (You can only have one spark context at a time the way we are running things here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625bcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cc823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/virchan/spark-3.3.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad3f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c03f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/17 11:58:05 WARN Utils: Your hostname, UbuntuTest resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/01/17 11:58:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/17 11:58:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Output hidden\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21851a5a",
   "metadata": {},
   "source": [
    "We use the Jupyter notebook magic commands to quickly write a text file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5d5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "first line\n",
    "second line\n",
    "third line\n",
    "fourth line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc1542",
   "metadata": {},
   "source": [
    "We now create an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401c7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile = sc.textFile(\"example.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767581f",
   "metadata": {},
   "source": [
    "Here, `textFile` is the RDD, and `sc` is the Spark contact that connects to a Spark cluster.\n",
    "\n",
    "We can perform actions or transformations on RDDs'. Losely speaking, RDDs' have <span style=\"color:blue\"> actions </span> which <span style=\"color:blue\"> return values </span> and <span style=\"color:orange\"> transformations </span> which <span style=\"color:orange\"> return pointers to new RDDs' </span>.\n",
    "\n",
    "<p>More precisely, an <strong><i><span style=\"color:blue\"> action</span></i></strong> (resp. a <strong><i> <span style=\"color:orange\">transformation</span></i></strong>) is a Spark operation that produces a <span style=\"color:blue\"> local object</span> (resp. an <span style=\"color:orange\"> RDD</span>.).</p>\n",
    "\n",
    "Let's start with the most basic action---`.count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922933e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681891b",
   "metadata": {},
   "source": [
    "The `.count()` action counts the number of elements in the RDD object. In our case, an element is a line in `example.txt`. Here is the `.first()` action, which returns the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86979f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first line'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb152f12",
   "metadata": {},
   "source": [
    "For more complicated tasks, we can perform transformations. For example, we can use the `.filter()` transformation to return a new RDD of a subset of items in the file. Let's go and try looking for lines that contain the word \"second\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f6be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "secfind = textFile.filter(lambda line: \"second\" in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f15ed",
   "metadata": {},
   "source": [
    "RDDs are lazily evaluated---you don't actually execute all those instructions of transformations until you perform an action. This is why it was fast for the above cell to run.\n",
    "\n",
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01eeef8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secfind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1bcf6",
   "metadata": {},
   "source": [
    "What does it mean? It tells you that it is some sort of RDD. It has a recipe of instructions to follow, but it does not actually execute them until you ask for the performance of the action.\n",
    "\n",
    "Now, let us perform the action `.collect()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c87d4a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['second line']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secfind.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a8d9e",
   "metadata": {},
   "source": [
    "We can also perform another action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf675705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secfind.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b54f3",
   "metadata": {},
   "source": [
    "## <a name = \"rddtransformaction\">RDD Transformations and Actions</a>\n",
    "\n",
    "Let's create a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ec56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example2.txt\n",
    "first\n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7d12d",
   "metadata": {},
   "source": [
    "and perform some transformations and actions it to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0892e545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example2.txt MapPartitionsRDD[7] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"example2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f003d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = sc.textFile(\"example2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb177f7",
   "metadata": {},
   "source": [
    "We perform the transformation that <u>splits every line into a list of words</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e72d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text_rdd.map(lambda line: line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffe79f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['the', 'third', 'line'],\n",
       " ['then', 'a', 'fourth', 'line']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975bd3a",
   "metadata": {},
   "source": [
    "Now, compare this with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e6dc0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'second line', 'the third line', 'then a fourth line']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a018e1d",
   "metadata": {},
   "source": [
    "If `.collect()` is called on the original text, we actually get each string line in that list.\n",
    "\n",
    "## <a name = \"mapvsflatmap\"><code>map</code> vs <code>flatMap</code></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4cd788",
   "metadata": {},
   "source": [
    "Repeat the previous steps with `flatMap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6e4d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'second',\n",
       " 'line',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " 'then',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'line']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f9d38",
   "metadata": {},
   "source": [
    "We have one single list of all the words in that text file.\n",
    "\n",
    "## <a name = \"keyandvaluepairs\">Key and Value Pairs</a>\n",
    "\n",
    "We use the code from the lecture notes to generate some fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3df85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing services.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile services.txt\n",
    "#EventId    Timestamp    Customer   State    ServiceID    Amount\n",
    "201       10/13/2017      100       NY       131          100.00\n",
    "204       10/18/2017      700       TX       129          450.00\n",
    "202       10/15/2017      203       CA       121          200.00\n",
    "206       10/19/2017      202       CA       131          500.00\n",
    "203       10/17/2017      101       NY       173          750.00\n",
    "205       10/19/2017      202       TX       121          200.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0790be",
   "metadata": {},
   "outputs": [],
   "source": [
    "services = sc.textFile(\"services.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5b2e8",
   "metadata": {},
   "source": [
    "Look at the first two lines of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b468174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e59c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# services.map(lambda line: line.split())\n",
    "\n",
    "# # PythonRDD[17] at RDD at PythonRDD.scala:53\n",
    "\n",
    "services.map(lambda line: line.split()).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "130697aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00',\n",
       " '206       10/19/2017      202       CA       131          500.00',\n",
       " '203       10/17/2017      101       NY       173          750.00',\n",
       " '205       10/19/2017      202       TX       121          200.00']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove hash-tag\n",
    "services.map(lambda line: line[1:] if line[0] == \"#\" else line).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba941233",
   "metadata": {},
   "source": [
    "Now, try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28bcb63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = services.map(lambda line: line[1:] if line[0] == \"#\" else line)\n",
    "\n",
    "clean = clean.map(lambda line: line.split())\n",
    "\n",
    "clean.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3f674",
   "metadata": {},
   "source": [
    "We then have our previous services mapped to a list of items, and we no longer have that hash tag.\n",
    "\n",
    "## <a name = \"reducebykey\">Reduce-by-Key Statement</a>\n",
    "\n",
    "Next, we practice **fields grabbing**. How can we get the total sales per state? We want to grab the \"State\" field and the \"Amount\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90f5436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = clean.map(lambda lst: (lst[3], lst[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7bbdf",
   "metadata": {},
   "source": [
    "The `reduceByKey` method takes in lambda expression, and it assumes the data are already in tuples form. More precisely, it takes the first element in the tuple as key, and perform the lambda expression on the last element. C.f. `GROUPBY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec01df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekey = pairs.reduceByKey(lambda amt1, amt2: amt1 + amt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d8314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'),\n",
       " ('NY', '100.00750.00'),\n",
       " ('TX', '450.00200.00'),\n",
       " ('CA', '200.00500.00')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rekey.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd61be8",
   "metadata": {},
   "source": [
    "Looks bad... Is that string concatenation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e61f6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekey = pairs.reduceByKey(lambda amt1, amt2: float(amt1) + float(amt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205ed76",
   "metadata": {},
   "source": [
    "Finally, we get the total sales by states. Let's continue this analysis by sorting the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bbb34af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', 850.0), ('CA', 700.0), ('TX', 650.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab (State, Amount)\n",
    "step1 = clean.map(lambda lst: (lst[3], lst[-1]))\n",
    "\n",
    "# Reduce by Key\n",
    "step2 = step1.reduceByKey(lambda amt1, amt2: float(amt1) + float(amt2))\n",
    "\n",
    "# Get rid of State, Amount titles\n",
    "step3 = step2.filter(lambda x: not x[0] == \"State\")\n",
    "\n",
    "# Sort Results by Amount\n",
    "step4 = step3.sortBy(lambda stAmount: stAmount[1], ascending = False)\n",
    "\n",
    "# Perorm Action\n",
    "step4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81696992",
   "metadata": {},
   "source": [
    "Packing and tuple are good for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9d477e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"ID\", \"State\", \"Amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90a52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(lst):\n",
    "    return lst[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31662caa",
   "metadata": {},
   "source": [
    "The problem with `func1` is, it is not readable when come back to it later. If a couple of days pass by, you are trying to remember the index tree and the last index. You would want to use packing and tuple instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c63a51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(id_st_amt):\n",
    "    #unpack values\n",
    "    (Id, st, amt) = id_st_amt\n",
    "    return amt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e86ec",
   "metadata": {},
   "source": [
    "Clearly, func2 is more readable than func1.\n",
    "\n",
    "## <a name = \"ref\">References</a>\n",
    "\n",
    "<ol style = \"type:1\">\n",
    "    <li>Jose Portilla. Python for Data Science and Machine Learning Bootcamp.</li>\n",
    "    <li>Apache Spark. <a href = \"https://spark.apache.org/docs/latest/api/python/\">https://spark.apache.org/docs/latest/api/python/</a>.</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
