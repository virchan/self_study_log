\documentclass[12pt,letterpaper,reqno]{amsart}


\include{Apackages} %this loads the packages


\makeindex

\author{Virgil Chan}
\title{Casella-Berger \\ Statistical Inference Solution: \\ Chapter 2}
\date{August 1, 2022}


\usetikzlibrary{patterns,positioning,arrows,chains,matrix,positioning,scopes} %options for tikzpicture

\addbibresource{bibliography.bib} %put your reference here


\makeatletter
\patchcmd{\@maketitle}
  {\ifx\@empty\@dedicatory}
  {\ifx\@empty\@date \else {\vskip3ex \centering\footnotesize\@date\par\vskip1ex}\fi
   \ifx\@empty\@dedicatory}
  {}{}
\patchcmd{\@adminfootnotes}
  {\ifx\@empty\@date\else \@footnotetext{\@setdate}\fi}
  {}{}{}
\makeatother

\include{Atheoremsenvironments}

\pdfpagewidth 8.5in
\pdfpageheight 11in

    
\include{Acommand}

\makeatletter
\tikzset{join/.code=\tikzset{after node path={%
\ifx\tikzchainprevious\pgfutil@empty\else(\tikzchainprevious)%
edge[every join]#1(\tikzchaincurrent)\fi}}}

\makeatother

%\tikzset{>=stealth',every on chain/.append style={join},
%        every join/.style={->}}

\newlength{\parindentsave}\setlength{\parindentsave}{\parindent}

\everymath{\displaystyle}

\numberwithin{equation}{subsection} 

\let\emptyset\varnothing

\hypersetup{colorlinks,citecolor=blue,linkcolor=blue}

\declaretheorem[numberwithin=section, shaded={rulecolor=black,
rulewidth=0.5pt, bgcolor={rgb}{1,1,1}}]{Theorem}

%\doublespacing

\setcounter{tocdepth}{4}

\begin{document}
\maketitle

\tableofcontents

\newpage
\section{Problem 2.1}

In each of the following find the pdf of $Y$. Show that the pdf integrates to 1.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item $Y = X^3$ and $f_X(x) = 42x^5(1-x)$, $0<x<1$
    \item $Y = 4X+3$ and $f_X(x) = 7e^{-7x}$, $0< x < \infty$
    \item $Y = X^2$ and $f_X(x) = 30x^2(1-x)^2$, $0< x< 1$
\end{enumerate}~\\

\begin{proof}[Solution] We begin by noting all conditions of \cite[Theorem 2.1.5 on page 51]{Berger-Casella} are satisfied in each case. We leave it to the reader to verify the pdf integrates to 1.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Let $g(x) = x^3$ for $x \in (0,1)$, then $g^{-1}(y) = y^{\frac{1}{3}}$ for $y \in (0,1)$, and
    
    \begin{align*}
        \Abs{\Dif{}{y} g^{-1}(y)} = \frac{1}{3 y^{\frac{2}{3}}}.
    \end{align*}
    Hence,

    \begin{align*}
        \fun{f_Y}{y} &= f_X \left( g^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g^{-1}(y)} \\
        &=  \left[ 42y^{\frac{5}{3}} \left( 1 -y^{\frac{1}{3}} \right) \right] \cdot \frac{1}{3 y^{\frac{2}{3}}} \\
        &= 14  \left( y - y^{\frac{4}{3}} \right)
    \end{align*}
    on $\mycal{Y} = (0,1)$.
    
    \item Let $g(x) = 4x + 3$ for $x \in (0, \infty)$, then $g^{-1}(y) = \frac{y-3}{4}$ for $y \in (3, \infty)$, and
    
    \begin{align*}
        \Abs{\Dif{}{y} g^{-1}(y)} = \frac{1}{4}.
    \end{align*}
    Hence,
    
    \begin{align*}
        \fun{f_Y}{y} &= f_X \left( g^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g^{-1}(y)} \\
        &=  \frac{7}{4} e^{-\frac{-7(y-3)}{4}}
    \end{align*}
    on $\mycal{Y} = (3, \infty)$.
    
    \item Let $g(x) = x^2$ for $x \in (0,1)$, then $g^{-1}(y) = y^{\frac{1}{2}}$ for $y \in (0,1)$, and
    
    \begin{align*}
        \Abs{\Dif{}{y} g^{-1}(y)} = \frac{1}{2} y^{-\frac{1}{2}}.
    \end{align*}
    Hence,
    
    \begin{align*}
        \fun{f_Y}{y} &= f_X \left( g^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g^{-1}(y)} \\
        &= 15y^{\frac{1}{2}} \left(1-y^{\frac{1}{2}} \right)^2
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.2}

In each of the following find the pdf of $Y$.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item $Y = X^2$ and $f_X(x) = 1$, $0 < x < 1$
    \item $Y = -\log(X)$ and $X$ has pdf
    
    \[ \mbox{$f_X(x) = \frac{(n+m+1)!}{n!m!}x^n (1-x)^m$, $0<x<1$, $m$, $n$ positive integers} \]
    
    \item $Y = e^X$ and $X$ has pdf
    
    \[ \mbox{$f_X(x) = \frac{1}{\sigma^2} xe^{-\frac{(x/\sigma)^2}{2}}$, $0< x< \infty$, $\sigma^2$ a positive constant} \]
\end{enumerate}~\\

\begin{proof}[Solution]
We begin by noting all conditions of \cite[Theorem 2.1.5 on page 51]{Berger-Casella} are satisfied in each case.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Let $g(x) = x^2$ for $x \in (0, 1)$, then $g^{-1}(y) = y^{\frac{1}{2}}$ for $y \in (0, 1)$, and
    
    \begin{align*}
        \Abs{\Dif{}{y} g^{-1}(y)} = \frac{1}{2} y^{-\frac{1}{2}}.
    \end{align*}
    Hence,
    
    \begin{align*}
        \fun{f_Y}{y} &= f_X \left( g^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g^{-1}(y)} \\
        &=  \frac{1}{2} y^{-\frac{1}{2}}
    \end{align*}
    on $\mycal{Y} = (0, 1)$.
    
    \item Let $g(x) = -\log(x)$ for $x \in (0, 1)$, then $g^{-1}(y) = e^{-y}$ for $y \in (0, \infty)$, and
    
    \begin{align*}
        \Abs{\Dif{}{y} g^{-1}(y)} = e^{-y}.
    \end{align*}
    Hence,
    
    \begin{align*}
        \fun{f_Y}{y} &= f_X \left( g^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g^{-1}(y)} \\
        &=  \frac{(n+m+1)!}{n!m!}e^{-ny} (1-e^{-y})^m
    \end{align*}
    on $\mycal{Y} = (0, \infty)$.
    
    \item Let $g(x) = e^x$ for $x \in (0, \infty)$, then $g^{-1}(y) = \log(y)$ for $y \in (1, \infty)$, and
    
    \begin{align*}
        \Abs{\Dif{}{y} g^{-1}(y)} = \frac{1}{y}.
    \end{align*}
    Hence,
    
    \begin{align*}
        \fun{f_Y}{y} &= f_X \left( g^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g^{-1}(y)} \\
        &=  \frac{\log(y)}{y\sigma^2}e^{-\frac{(\log(y)/\sigma)^2}{2}}
    \end{align*}
    on $\mycal{Y} = (0, \infty)$.
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.3}

Suppose $X$ has the geometric pmf $f_X(x) = \frac{1}{3} \left( \frac{2}{3} \right)^x$, $x = 0, 1, 2, \cdots$. Determine the probability distribution of $Y = X/(X+1)$. Note that here both $X$ and $Y$ are discrete random variables. To specify the probability distribution of $Y$, specify its pmf.

\begin{proof}[Solution]

\begin{align*}
    \fun{f_Y}{y} &= \fun{P}{Y = y} \\
                 &= \fun{P}{\frac{X}{X+1} = y} \\
                 &= \fun{P}{X = \frac{y}{1-y}} \\
                 &= \fun{f_X}{\frac{y}{1-y}} \\
                 &= \frac{1}{3} \left( \frac{2}{3} \right)^{\frac{y}{1-y}}
\end{align*}
on $\mycal{Y} = \SET{\frac{x}{x+1}}{\mbox{$x = \frac{1}{3} \left( \frac{2}{3} \right)^k$ for some $k \in \D{N} \cup \SETT{0}$}}$
\end{proof}

\newpage
\section{Problem 2.4}

Let $\lambda$ be a fixed positive constant, and define the function $f(x)$ by $f(x) = \frac{1}{2} \lambda e^{-\lambda x}$ if $x \geq 0$ and $f(x) = \frac{1}{2} \lambda e^{\lambda x}$ if $x < 0$.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Verify that $f(x)$ is a pdf.
    \item If $X$ is a random variable with pdf given by $f(x)$, find $\fun{P}{X < t}$ for all $t$. Evaluate all integrals.
    \item Find $\fun{P}{\Abs{X} < t}$ for all $t$. Evaluate all integrals.
\end{enumerate}~\\

\begin{proof}[Solution]~\\

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Check the conditions listed on \cite[Theorem 1.6.5 on page 36]{Berger-Casella} for $f(x)$.
    
    \item
    
    \begin{align*}
        \fun{P}{X < t} &= \myint{f(x)}{x}{-\infty}{t} \\
                       &= \left\{ \begin{array}{cl}
                            \myint{\frac{1}{2} \lambda e^{\lambda x}}{x}{-\infty}{t} & \mbox{if $t < 0$}, \\
                            \myint{\frac{1}{2} \lambda e^{\lambda x}}{x}{-\infty}{0} + \myint{\frac{1}{2} \lambda e^{-\lambda x}}{x}{0}{t} & \mbox{if else},
                       \end{array} \right. \\
                       &=  \left\{ \begin{array}{cl}
                            \frac{e^{\lambda t}}{2} & \mbox{if $t < 0$}, \\
                            1 - \frac{1}{2}e^{-\lambda t} & \mbox{if else}.
                       \end{array} \right.
    \end{align*}
    
    \item
    
    \begin{align*}
        \fun{P}{\Abs{X} < t} &= \fun{P}{-t < X < t} \\
                             &= \fun{P}{X < t} - \fun{P}{X < -t} \\
                             &= \left( 1 - \frac{1}{2}e^{-\lambda t} \right) -  \frac{e^{-\lambda t}}{2} & \left(\mbox{part (b)}\right) \\
                             &= 1 - e^{-\lambda t}
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.5}

Use \cite[Theorem 2.1.8 on page 53]{Berger-Casella} to find the pdf of $Y$ in \cite[Example 2.1.2 on page 49]{Berger-Casella}. Show that the same answer is obtained by differentiating the cdf given in \cite[Equation 2.1.6 on page 49]{Berger-Casella}.

\begin{proof}[Solution]
Partition the interval $(0, 2\pi)$ into $\SETT{A_i}_{i=0}^4$, with

\begin{align*}
    A_i &= \left\{ \begin{array}{cl}
         \SETT{0} & \mbox{if $i = 0$}, \\
         \Interval{(}{\frac{(i-1)\pi}{2}}{\frac{i \pi }{2}}{)} & \mbox{if $i > 0$}.
    \end{array} \right.
\end{align*}
For each $i$, write $g_i(x) = \sin^2(x)$ on $A_i$. Then

\begin{align*}
    \fun{g^{-1}_1}{y} &= \arcsin(\sqrt{y}) \\
    \fun{g^{-1}_2}{y} &= \pi - \arcsin(\sqrt{y}) \\
    \fun{g^{-1}_3}{y} &= \pi + \arcsin(\sqrt{y}) \\
    \fun{g^{-1}_4}{y} &= 2\pi - \arcsin(\sqrt{y})
\end{align*}
Therefore,

\begin{align*}
    \fun{f_Y}{y} &= \sum_{i=1}^4 f_X \left( g_i^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g_i^{-1}(y)} \\
    &= 4 \left(\frac{1}{2\pi} \right) \left[ \frac{1}{2 \sqrt{y-y^2}} \right] \\
    &= \frac{1}{\pi \sqrt{y-y^2}}
\end{align*}
on $\mycal{Y} = (0,1)$.
\end{proof}

\newpage
\section{Problem 2.6}
In each of the following find the pdf of $Y$ and show that the pdf integrates to 1.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item $f_X(x) = \frac{1}{2} e^{-\Abs{x}}$, $-\infty < x < \infty$; $Y = \Abs{X}^3$
    \item $f_X(x) = \frac{3}{8} \left( x + 1 \right)^2$, $-1 < x < 1$; $Y = 1 - X^2$
    \item $f_X(x) = \frac{3}{8} \left( x + 1 \right)^2$, $-1 < x < 1$; $Y = 1 - X^2$ if $X \leq 0$ and $Y = 1-X$ if $X > 0$
\end{enumerate}

\begin{proof}[Solution] We note that \cite[Theorem 2.1.8 on page 53]{Berger-Casella} applies to all cases, and let readers to verify the pdf integrates to 1.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Parition $\Interval{(}{-\infty}{\infty}{)}$ into
    
    \begin{align*}
        A_0 &= \SETT{0} \\
        A_1 &= \Interval{(}{-\infty}{0}{)} \\
        A_2 &= \Interval{(}{0}{\infty}{)}
    \end{align*}
    and define
    
    \[ g_i(x) = \left\{ \begin{array}{cl}
         x^3 & \mbox{if $i$ even,}\\
         -x^3 & \mbox{if $i$ odd}
    \end{array} \right. \]
    on $A_i$. Then
    
    \begin{align*}
        \fun{f_Y}{y} &= \sum_{i=1}^2 f_X \left( g_i^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g_i^{-1}(y)} \\
        &= \frac{1}{3} y^{-\frac{2}{3}} e^{-y^{1/3}}
    \end{align*}
    on $\mycal{Y} = (0, \infty)$.
    
    \item Partition $(-1, 1)$ into     
    \begin{align*}
        A_0 &= \SETT{0} \\
        A_1 &= \Interval{(}{-1}{0}{)} \\
        A_2 &= \Interval{(}{0}{1}{)}
    \end{align*}
    and define
    
    \[ g_i(x) = 1-x^2 \]
    on $A_i$. Then
    
        \begin{align*}
        \fun{f_Y}{y} &= \sum_{i=1}^2 f_X \left( g_i^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g_i^{-1}(y)} \\
        &= \frac{3}{8} \left( \frac{1}{ \sqrt{1-y}} + \sqrt{1-y} \right)
    \end{align*}
    on $\mycal{Y} = (0, 1)$.
    
    \item Partition $(-1,1)$ just as in part (b), and define
    
    \[ g_i(x) = \left\{ \begin{array}{cl}
        1-x^2 & \mbox{on $A_1$,} \\
        1-x & \mbox{on $A_2$.}
    \end{array} \right. \]
    Then 
    \begin{align*}
        \fun{f_Y}{y} &= \sum_{i=1}^2 f_X \left( g_i^{-1} \left( y \right) \right) \cdot \Abs{\Dif{}{y} g_i^{-1}(y)} \\
        &= \frac{3}{16} \frac{1}{\sqrt{1-y}} \left( 1 - \sqrt{1-y} \right)^2 +\frac{3}{8} (2-y)^2
    \end{align*}
    on $\mycal{Y} = (0, 1)$.
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.7}

Let $X$ have pdf $f_X(x) = \frac{2}{9}(x+1)$, $-1 \leq x \leq 2$.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Find the pdf of $Y = X^2$. Note that \cite[Theorem 2.1.8 on page 53]{Berger-Casella} is not directly applicable in this problem.
    \item Show that \cite[Theorem 2.1.8 on page 53]{Berger-Casella} remains valid if the sets $A_0, A_1, \cdots, A_k$ contain $\mycal{X}$, and apply the extension to solve part (a) using $A_0 = \emptyset$, $A_1 = (-2,0)$, and $A_2 = (0,2)$.
\end{enumerate}~\\

\begin{proof}[Solution]~\\
\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item 
    
    \begin{align*}
        \fun{P}{Y \leq y} &= \fun{P}{X^2 \leq y} \\
                          &= \left\{ \begin{array}{cl}
                               \fun{P}{-\sqrt{y} \leq X \leq \sqrt{y}} & \mbox{if $y < 1$,} \\
                               \fun{P}{-1 \leq X \leq \sqrt{y}} & \mbox{if $1 \leq y \leq 4$.}
                          \end{array} \right. \\
                          &= \left\{ \begin{array}{cl}
                               \myint{f_X(x)}{x}{-\sqrt{y}}{\sqrt{y}} & \mbox{if $y < 1$,} \\
                               \myint{f_X(x)}{x}{-1}{\sqrt{y}} & \mbox{if $1 \leq y \leq 4$.}
                          \end{array} \right. \\
                         &= \left\{ \begin{array}{cl}
                               \frac{4 \sqrt{y}}{9} & \mbox{if $y < 1$,} \\
                               \frac{1}{9} \left( 1 + \sqrt{y} \right)^2 & \mbox{if $1 \leq y \leq 4$.}
                          \end{array} \right. \\
    \end{align*}
    on $\mycal{Y} = (0,4)$.
    
    \item C.f. Problem 2.6.
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.8}

In each of the following show that the given function is a cdf and find $F^{-1}_X(y)$.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item
    
    \[ F_X(x) = \left\{ \begin{array}{cl}
         0 & \mbox{if $x < 0$} \\
         1 - e^{-x} & \mbox{if $x \geq 0$}
    \end{array} \right. \]
    
        \item
    
    \[ F_X(x) = \left\{ \begin{array}{cl}
         e^x/2 & \mbox{if $x < 0$} \\
         1/2 & \mbox{if $0 \leq x < 1$} \\
         1-(e^{1-x}/2) & \mbox{if $1 \leq x$}
    \end{array} \right. \]
    
        \item
    
    \[ F_X(x) = \left\{ \begin{array}{cl}
         e^x/4 & \mbox{if $x < 0$} \\
         1 - (e^{-x}/4) & \mbox{if $x \geq 0$}
    \end{array} \right. \]
\end{enumerate}~\\

\begin{proof}[Solution] To show a function is cdf, we verify the conditions in \cite[Theorem 1.5.3 on page 31]{Berger-Casella}, which are routine computations.

\begin{enumerate}[label = (\alph*),leftmargin=*]
    \item 
    
    \[ F_X^{-1}(y) = -\log(1-y) \]
    
    \item 
    
    \[ F_X^{-1}(y) = \left\{ \begin{array}{cl}
         \log(2y) & \mbox{if $0 \leq y \leq \frac{1}{2}$} \\
         1 -\log(2(1-y)) & \mbox{if $\frac{1}{2} \leq y \leq 1$}
    \end{array} \right. \]
    
    \item 
    
    \[ F_X^{-1}(y) = \left\{ \begin{array}{cl}
         \log(4y) & \mbox{if $0 \leq y \leq \frac{1}{4}$} \\
         -\log(4(1-y)) & \mbox{if $\frac{1}{4} \leq y \leq 1$}
    \end{array} \right. \]
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.9}

If the random variable $X$ has pdf

\[ f(x) = \left\{ \begin{array}{cl}
     \frac{x-1}{2} & \mbox{$1<x<3$,} \\
     0 & \mbox{otherwise,}
\end{array} \right. \]
find a monotone function $u(x)$ such that the random variable $Y = u(X)$ has uniform(0,1) distribution.

\begin{proof}[Solution] This is a direct application of \cite[Theorem 2.1.10 on page 54]{Berger-Casella}. The cdf is given by

\begin{align*}
    F_X(x) &= \left\{ \begin{array}{cl}
         0 & \mbox{if $x \leq 1$} \\
         \myint{f(t)}{t}{1}{x} & \mbox{if $1 < x < 3$} \\
         1 & \mbox{if else}
    \end{array} \right. \\
    &= \left\{ \begin{array}{cl}
         0 & \mbox{if $x \leq 1$} \\
         \frac{(x-1)^2}{4} & \mbox{if $1 < x < 3$} \\
         1 & \mbox{if else}
    \end{array} \right.
\end{align*}
which is clearly monotone. So $u(x) = F_X(x)$.
\end{proof}

\newpage
\section{Problem 2.11}

Let $X$ have the standard normal pdf, $f_X(x) = (1/ \sqrt{2\pi}) e^{-x^2/2}$.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Find $EX^2$ directly, and then by using the pdf of $Y = X^2$ from \cite[Example 2.1.7 on page 52]{Berger-Casella} and calculating $EY$.
    
    \item Find the pdf of $Y = \Abs{X}$, and find its mean and variance.
\end{enumerate}~\\

\begin{proof}[Solution]~\\

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item First we have
    
    \begin{align*}
        EX^2 &= \myint{x^2 f_X(x)}{x}{-\infty}{\infty} & \left(\mbox{\cite[Definition 2.2.1 on page 55]{Berger-Casella}} \right) \\
        &= \myint{\frac{x^2}{\sqrt{2\pi}} e^{-x^2/2}}{x}{-\infty}{\infty} \\
        &= \frac{1}{\sqrt{2\pi}} \left[ xe^{-x^2/2} \vert^{x = \infty}_{x = -\infty} - \myint{e^{-x^2/2}}{x}{-\infty}{\infty} \right] \\
        &= 1.
    \end{align*}
    
    Secondly, by \cite[Example 2.1.7 on page 52]{Berger-Casella}, the pdf of $Y$ is given by
    
    \begin{align*}
        f_Y(y) &= \frac{1}{2 \sqrt{y}} \left[ f_X( \sqrt{y}) + f_X(-\sqrt{y}) \right] \\
        &= \frac{1}{\sqrt{2 \pi y}} e^{-y/2}.
    \end{align*}
    Therefore,
    
    \begin{align*}
        EY &= \myint{yf_Y(y)}{y}{0}{\infty} \\
           &= \myint{\sqrt{\frac{y}{2\pi}} e^{-y/2}}{y}{0}{\infty} \\
           &= 1
    \end{align*}
    
    \item Using \cite[Theorem 2.1.8 on page 53]{Berger-Casella}, $Y$ has pdf
    
    \begin{align*}
        f_Y(y) &= f_X(y) + f_X(-y) \\
               &= \sqrt{\frac{2}{\pi}} e^{-y^2/2}
    \end{align*}
    Therefore,
    
    \begin{align*}
        EY &= \myint{yf_Y(y)}{y}{0}{\infty} = \sqrt{\frac{2}{\pi}} \\
         \Var{Y} &= EY^2 - (EY)^2 = 1 - \frac{2}{\pi}
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.12} See \cite[page 77]{Berger-Casella} for the problem statement.

\begin{proof}[Solution] We know

\[ y = \underbrace{d \tan(x)}_{g(x)} \]
for $x \in (0, \pi/2)$, and

\begin{align*}
    \Dif{g^{-1}}{y} &= \Dif{}{y} \arctan \left( \frac{y}{d} \right) \\
                    &= \frac{d}{d^2 + y^2}.
\end{align*}
Therefore, \cite[Theorem 2.1.5 on page 51]{Berger-Casella} gives

\begin{align*}
    f_Y(y) &= f_X(g^{-1}(y)) \Abs{\Dif{g^{-1}}{y}} \\
           &= \frac{1}{\frac{\pi}{2} - 0} \cdot \frac{d}{d^2 + y^2} \\
           &= \frac{2d}{\pi (d^2 + y^2)}
\end{align*}
on $\mycal{Y} = (0, \infty)$, which is the Cauchy distribution. In particular, $EY = \infty$.
\end{proof}

\newpage
\section{Problem 2.13}

Consider a sequence of independent coin flips, each of which has probability $p$ of being heads. Define a random variable $X$ as the length of the run (of either heads or tails) started by the first trail. (For example, $X = 3$ if either TTTH or HHHT is observed.) Find the distribution of $X$, and find $EX$.

\begin{proof}[Solution] $X$ has pmf

\[ P(X = k) = (1-p)^kp + p^k(1-p). \]
Therefore,

\begin{align*}
    EX &= \sum_{k=1}^{\infty} k \left[ (1-p)^kp + p^k(1-p) \right] \\
       &= (1-p)p \left[ \sum_{k=1}^{\infty} k(1-p)^{k-1} + \sum_{k=1}^{\infty} kp^{k-1} \right] \\
       &= (1-p)p \left( \frac{1}{p^2} + \frac{1}{(1-p)^2} \right)
\end{align*}
\end{proof}

\newpage
\section{Probblem 2.14}

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Let $X$ be a continuous, nonnegative random variable [$f(x) = 0$ for $x < 0$]. Show that
    
    \[ EX = \myint{[1-F_X(x)]}{x}{0}{\infty}, \]
    where $F_X(x)$ is the cdf of $X$.
    
    \item Let $X$ be a discrete random variable whose range is the nonnegative integers. Show that
    
    \[ EX = \sum_{k=0}^{\infty} (1-F_X(k)), \]
    where $F_X(k) = \fun{P}{X \leq k}$. Compare this with part (a).
\end{enumerate}~\\

\begin{proof}[Solution]~\\

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item 
    
    \begin{align*}
        \myint{[1-F_X(x)]}{x}{0}{\infty} &= \myint{P(X > x)}{x}{0}{\infty} \\
        &= \myint{\myint{f_X(y)}{y}{x}{\infty}}{x}{0}{\infty} \\
        &= \myint{\myint{f_X(y)}{x}{0}{y}}{y}{0}{\infty} \\
        &= \myint{yf_X(y)}{y}{0}{\infty} \\
        &= EX
    \end{align*}
    
    \item
    
    \begin{align*}
        EX &= \sum_{k=0}^{\infty} k \fun{P}{X = k} \\
           &= \sum_{k=1}^{\infty} \fun{P}{X=k} + \sum_{k=2}^{\infty} \fun{P}{X=k} + \sum_{k=3}^{\infty} \fun{P}{X=k} + \cdots \\
           &= \fun{P}{X > 0} + \fun{P}{X > 1} + \fun{P}{X > 2} + \cdots \\
           &= \sum_{k=0}^{\infty} 1-F_X(k)
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.18}

Show that if $X$ is a continuous random variable, then

\[ \min_a E \Abs{X-a} = E \Abs{X-m}, \]
where $m$ is the median of $X$.

\begin{proof}[Solution] The expected value of $\Abs{X-a}$ is given by

\begin{align*}
    E\Abs{X-a} &= \myint{\Abs{x-a} f_X(x)}{x}{-\infty}{\infty} \\
    &= \myint{(x-a)f_X(x)}{x}{a}{\infty} - \myint{(x-a)f_X(x)}{x}{-\infty}{a} \\
\end{align*}
Differentiate with respect to $a$ we have

\begin{align*}
    \Dif{}{a} E\Abs{X-a} &= \Dif{}{a} \left[ \myint{(x-a)f_X(x)}{x}{a}{\infty} \right] - \Dif{}{a} \left[ \myint{(x-a)f_X(x)}{x}{-\infty}{a} \right] \\
    &= \myint{\dif{}{a}\left[(x-a)f_X(x) \right]}{x}{a}{\infty} - \myint{\dif{}{a} \left[ (x-a)f_X(x) \right]}{x}{-\infty}{a} \\
    &= \myint{f_X(x)}{x}{-\infty}{a} - \myint{f_X(x)}{x}{a}{\infty} \\
    &= \fun{P}{X \leq a} - \fun{P}{X > a}.
\end{align*}
In particular,

\[ 1- 2\fun{P}{X > a} = \Dif{}{a} E\Abs{X-a} = 1 - 2\fun{P}{X \leq a}. \]
Therefore, the solution to

\[ \Dif{}{a} E\Abs{X-a} = 0 \]
is the median $m$. Moreover, $m$ is a minima because

\begin{align*}
    \left.\Dif{^2}{a^2}\right\vert_{a=m} E \Abs{X-a} = 2f_X(m) > 0.
\end{align*}
\end{proof}

\newpage
\section{Problem 2.19}

Prove that

\[ \Dif{}{a} E(X-a)^2 = 0 \iff EX = a \]
by differentiating the integral. Verify, using calculus, that $a = EX$ is indeed a minimum. List the assumptions about $F_X$ and $f_X$ are needed.

\begin{proof}[Solution]
We have

\begin{align*}
    \Dif{}{a} E(X-a)^2 &= \Dif{}{a} \myint{(x-a)^2 f_X(x)}{x}{-\infty}{\infty} \\
    &= \myint{\dif{}{a} \left[ (x-a)^2 f_X(x) \right]}{x}{-\infty}{\infty} \\
    &=-2 \myint{(x-a)f_X(x)}{x}{-\infty}{\infty} \\
    &= -2 E(X-a)
\end{align*}
Therefore,

\begin{align*}
    \Dif{}{a} E(X-a)^2 = 0 &\iff -2E(X-a) = 0 \\
                           &\iff E(X-a) = 0 \\
                           &\iff EX = a.
\end{align*}
To verify $a = EX$ is minimum, we compute the second derivative

\[ \Dif{^2}{a^2} E(X-a)^2 = 2 > 0.\]
\end{proof}

\newpage
\section{Proboelm 2.21}

Prove the ``two-way'' rule for expectations, \cite[Equation (2.2.5) on page 58]{Berger-Casella}, which says $Eg(X) = EY$ where $Y = g(X)$. Assume that $g(x)$ is a monotone function.

\begin{proof}[Solution]
\begin{align*}
    Eg(X) &= \myint{g(x) f_X(x)}{x}{\D{R}}{} \\
          &= \myint{y f_X(g^{-1}(y)) \cdot \Dif{g^{-1}}{y}}{y}{\D{R}}{} \\
          &= \myint{y f_Y(y)}{y}{\D{R}}{} \\
          &= EY
\end{align*}
\end{proof}

\newpage
\section{Problem 2.22}

Let $X$ have the pdf

\[ f(x) = \frac{4}{\beta^3 \sqrt{\pi}} x^2 e^{-x^2/ \beta^2}, \ 0<x<\infty, \ \beta > 0. \]

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Verify that $f(x)$ is a pdf.
    \item Find $EX$ and $\Var{X}$.
\end{enumerate}~\\

\begin{proof}[Solution]~\\

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item  \cite[Theorem 1.6.5 on page 36]{Berger-Casella}.
    \item
    
    \begin{align*}
        EX 
        &= \myint{xf(x)}{x}{0}{\infty} \\
        &= \myint{\frac{4}{\beta^3 \sqrt{\pi}} x^3 e^{-x^2/ \beta^2}}{x}{0}{\infty} \\
        &= \frac{4}{\beta^3 \sqrt{\pi}} \myint{x^3 e^{-x^2/ \beta^2}}{x}{0}{\infty} \\
        &= \left( \frac{4}{\beta^3 \sqrt{\pi}} \right) \left(- \frac{\beta^2}{2} \right) \left( - \myint{2xe^{-x^2/\beta^2}}{x}{0}{\infty} \right) \\
        &= \left( \frac{4}{\beta^3 \sqrt{\pi}} \right) \left( \frac{\beta^4}{2} \right) \\
        &= \frac{2\beta}{\sqrt{\pi}}
    \end{align*}
    and similarly,
    
    \begin{align*}
        EX^2 &= \frac{3\beta^2}{2}, \\
        \Var{X} &= EX^2 - (EX)^2 \\
                &= \beta^2 \left[ \frac{3}{2} - \frac{4}{\pi} \right]
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.23}

Let $X$ have the pdf 

\[ f(x) = \frac{1}{2}(1+x), \ -1 < x < 1. \]
\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Find the pdf of $Y = X^2$.
    \item Find $EY$ and $\Var{Y}$.
\end{enumerate}~\\

\begin{proof}[Solution]~\\
\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Define $g_i(x) = x^2$ on $A_1 = (-1,0)$ and $A_2 = (0,1)$. Then
    
    \begin{align*}
        f_Y(y) &= \left[ f(-\sqrt{y}) + f(\sqrt{y}) \right] \cdot \frac{1}{2\sqrt{y}} \\
        &= \frac{1}{2\sqrt{y}}
    \end{align*}
    on $\mycal{Y} = (0,1)$.
    
    \item We have
    
    \begin{align*}
        \myint{y^n f_Y(y)}{y}{0}{1} &= \frac{1}{2} \myint{y^{n-1/2}}{y}{0}{1} \\
        &= \frac{1}{2n+1}.
    \end{align*}
    This gives
    
    \begin{align*}
        EY &= \frac{1}{3} \\
        EY^2 &= \frac{1}{5} \\
        \Var{Y} &= \frac{4}{45}
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Problem 2.26}

Let $f(x)$ be a pdf and let $a$ be a number such that, for all $\ve > 0$, $f(a + \ve) = f(a - \ve)$. Such a pdf is said to be summetric about the point $a$.

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Give three examples of symmetric pdfs.
    \item Show that if $X \sim f(x)$, symmetric, then the median of $X$ (see Exercise 2.17) is the number $a$.
    \item Show that if $X \sim f(x)$, symmetric and $EX$ exists, then $EX = a$.
    \item Show that $f(x) = e^{-x}$, $x \geq 0$, is not a symmetric pdf.
    \item Show that for the pdf in part (d), the median is less than the mean.
\end{enumerate}~\\

\begin{proof}[Solution]~\\
\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item Cauchy, Normal, Uniform.
    
    \item By change of variable, we may assume $a = 0$. The statement thus becomes: the median of an even pdf is 0, which is obvious because
    
    \begin{align*}
         1 &= \myint{f(x)}{x}{-\infty}{\infty} \\
         &= \myint{f(x)}{x}{-\infty}{0} + \myint{f(x)}{x}{0}{\infty} \\
         &= 2 \myint{f(x)}{x}{-\infty}{0} \\
         &= 2 \fun{P}{X \leq 0}
    \end{align*}
    
    \item Following the same logic in part (b), the statement becomes: the expected value of an even pdf $f(x)$ is 0.
    
    This is true because the funcion $xf(x)$ is odd, hence
    
    \begin{align*}
        EX &= \myint{xf(x)}{x}{-\infty}{\infty} \\
           &= 0
    \end{align*}
    
    \item If $f(x) = e^{-x}$ were symmetric, then it would be symmetric at $x = EX$ for $X \sim f(x)$ by part (c). In particular,
    
    \begin{align*}
        EX &= \myint{xe^{-x}}{x}{0}{\infty} \\
           &= 1.
    \end{align*}
    However, a direct computation shows $1$ is not the median of $X$, contradicting part (b). Therefore it is not symmetric.
    
    \item As computed in part (d), the mean is $1$. The claim follows from the computation
    
    \begin{align*}
        \myint{f(x)}{x}{0}{\mbox{mean}} &= \myint{e^{-x}}{x}{0}{1} \\
                                        &= \frac{e-1}{e} \\
                                        &> \frac{1}{2}
    \end{align*}
\end{enumerate}
\end{proof}

\newpage
\section{Exercise 2.32}

We compute

\begin{align*}
    \left.\Dif{}{t} \right\vert_{t=0} \fun{S}{t}
    &= \left.\Dif{}{t} \right\vert_{t=0} \fun{\log}{\fun{M_X}{t}} \\
    &= \frac{\fun{\dot{M}_X}{0}}{\fun{M_X}{0}} \\
    &= EX,
\end{align*}
and

\begin{align*}
    \left.\Dif{^2}{t^2} \right\vert_{t=0} \fun{S}{t}
    &= \frac{\fun{\ddot{M}_X}{0} \fun{M_X}{0} - \fun{\dot{M}^2_X}{0}}{\fun{M^2_X}{0}} \\
    &= EX^2 - (EX)^2 \\
    &= \Var{X}.
\end{align*}

\newpage
\section{Exercise 2.33}

\begin{enumerate}[label=(\alph*),leftmargin=*]
    \item The mgf is
    
    \begin{align*}
        \fun{M_X}{t} &= \sum_{x=0}^{\infty} e^{tx} \cdot \frac{e^{-\lambda} \lambda^x}{x!} \\
        &= e^{-\lambda} \sum_{x=0}^{\infty} \frac{\left(  \lambda e^t \right)^x}{x!} \\
        &= e^{-\lambda} \cdot e^{\lambda e^t} \\
        &= e^{\lambda \left( e^t - 1 \right)}.
    \end{align*}
    The moments are
    
    \begin{align*}
        EX &= \left.\Dif{}{t}\right\vert_{t=0} M_X(t) \\
        &= \left. \lambda e^t \cdot e^{\lambda \left( e^t - 1 \right)} \right\vert_{t=0} \\
        &= \lambda, \\
        \\
        EX^2 &= \left.\Dif{^2}{t^2}\right\vert_{t=0} M_X(t) \\
        &= \left. \lambda \left( 1 + e^t \lambda \right) \cdot e^{\lambda \left( e^t - 1 \right)} \right\vert_{t=0} \\
        &= \lambda^2 + \lambda.
    \end{align*}
    Therefore,
    
    \[ \Var{X} = \lambda. \]
    
    \item The mgf is
    
    \begin{align*}
        \fun{M_X}{t} &= \sum_{x=0}^{\infty} e^{tx} p(1-p)^x \\
        &= \sum_{x=0}^{\infty} p \left[ e^t (1-p) \right]^x \\
        &= \frac{p}{1-e^t(1-p)}
    \end{align*}
    
    The moments are
    
    \begin{align*}
        EX &= \frac{1-p}{p}, \\
        \\
        EX^2 &= \frac{(2-p)(1-p)}{p^2}
    \end{align*}
    Therefore,
    
    \begin{align*}
        \Var{X} = \frac{1-p}{p^2}.
    \end{align*}
    
    \item The mgf is
    
    \begin{align*}
        \fun{M_X}{t} &= \myint{e^{tx} \cdot \frac{e^{-(x-\mu)^2/(2 \sigma^2)}}{\sqrt{2\pi} \sigma}}{x}{-\infty}{\infty} \\
        &= \myint{\frac{e^{- \left( x^2 - 2x \mu + \mu^2 - 2 \sigma^2 tx \right)/(2 \sigma^2)}}{\sqrt{2\pi} \sigma}}{x}{-\infty}{\infty} \\
        &= e^{ \frac{2\mu \sigma^2t + \sigma^4 t^2}{2 \sigma^2}} \cdot \myint{\frac{e^{-\frac{\left[ x - \left( \mu + \sigma^2 t \right) \right]^2}{2 \sigma^2}}}{\sqrt{2\pi} \sigma}}{x}{-\infty}{\infty} \\
        &= e^{\mu t + \frac{\sigma^2 t^2}{2}}.
    \end{align*}
    The moments are
    
    \begin{align*}
        EX &= \left. \Dif{}{t} \right\vert_{t=0} \fun{M_X}{t} \\
        &= \mu, \\
        \\
        EX^2 &= \left. \Dif{^2}{t^2} \right\vert_{t=0}  \fun{M_X}{t} \\
        &= \sigma^2 + \mu^2.
    \end{align*}
    Therefore,
    
    \begin{align*}
        \Var{X} &= EX^2 - (EX)^2 \\
                &= \sigma^2
    \end{align*}
\end{enumerate}

\newpage
\nocite{*}
\printbibliography

\end{document}